{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import printoptions\n",
    "import requests\n",
    "import tarfile\n",
    "import random\n",
    "import json\n",
    "from shutil import copyfile\n",
    "import pathlib\n",
    "\n",
    "from typing import List, Dict\n",
    "from multiprocessing import Pool\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from tools import get_transform, get_instance_segmentation_model, ObjectDetectionDataSet\n",
    "from tools import map_class_to_int, save_json, read_json, get_filenames_of_path, adapt_data\n",
    "from tools import checkpoint_save, show_sample, MutilabelClassificationDataset, evaluate\n",
    "from tools import MLCDataset, MLCDataLoader\n",
    "from backbones import GetModel, GetModelNM, BuildModel\n",
    "from torchmets import sklearn_metrics, compute_full_metrics, compute_tracking_metrics\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import re\n",
    "from math import isnan\n",
    "from os.path import isfile, join\n",
    "from neptune.types import File\n",
    "from torchsummary import summary\n",
    "from tools import TorchXRayVisionNorm\n",
    "import itertools as itl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'OWNER': 'rubsini', \n",
    "          'PROJECT': 'ApplePlantDiseases',\n",
    "          'PARTITION':'../Data/Splits/split1.json',\n",
    "          'IMGS_PATH':'../Data/224/', \n",
    "          'SAVE_PATH': 'Checkpoints/', \n",
    "          'SAVE_DIR':'Result_Tables_Archs', \n",
    "          'SAVE_FREQ': 50, \n",
    "          'EXP_TYPE':['Initial Test Exp' ,'General Board'],\n",
    "          'LOG_MODEL': True,  \n",
    "          'BACKBONE': 'resnet50', \n",
    "          'MODEL_FREEZE': True, \n",
    "          'I_WEIGHTS': False,\n",
    "          'BATCH_SIZE': 16, \n",
    "          'LR': 1e-3, \n",
    "          'EPOCHS': 50, \n",
    "          'N_WORKERS': 1,\n",
    "          'SAVE_FREQ': 50,\n",
    "          'WEIGHT_DECAY': 5e-5,\n",
    "        #   'RESIZE': 224,\n",
    "          'CROP_SIZE': 512,\n",
    "          'ROTATION_RANGE': 15,\n",
    "          'TRANSLATION': 0.10,\n",
    "          'SCALE': (0.85,1.15),\n",
    "          \"IMG_MEAN\":[0.485, 0.456, 0.406],\n",
    "          \"IMG_STD\":[0.229, 0.224, 0.225]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                                    #   transforms.RandomCrop(params['CROP_SIZE']),\n",
    "                                      # transforms.RandomAffine(params['ROTATION_RANGE'], translate=(params['TRANSLATION'], params['TRANSLATION']), scale=params['SCALE']),\n",
    "                                      transforms.Resize((params['CROP_SIZE'],params['CROP_SIZE'],)),\n",
    "                                      # transforms.ToTensor(),\n",
    "                                      # transforms.Normalize(params[\"IMG_MEAN\"], params[\"IMG_STD\"])\n",
    "                                      ])\n",
    "val_transform = transforms.Compose([\n",
    "                                    transforms.Resize((params['CROP_SIZE'],params['CROP_SIZE'],)),\n",
    "                                    # transforms.ToTensor(),\n",
    "                                    # transforms.Normalize(params[\"IMG_MEAN\"], params[\"IMG_STD\"])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 18632 (1.00%)\n",
      "Train data: 13044 (0.70%)\n",
      "Val Data:   2774  (0.15%)\n",
      "Test Data:  2814  (0.15%)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MLCDataset(params['PARTITION'], params['IMGS_PATH'], 'Train') #, train_transform)\n",
    "val_dataset = MLCDataset(params['PARTITION'], params['IMGS_PATH'], 'Val') #, train_transform)\n",
    "test_dataset = MLCDataset(params['PARTITION'], params['IMGS_PATH'], 'Test') #, train_transform)\n",
    "\n",
    "lt = len(train_dataset)+len(val_dataset)+len(test_dataset)\n",
    "ltr,ptr,lvd,pvd,lts,pts = len(train_dataset), len(train_dataset)/lt, len(val_dataset), len(val_dataset)/lt, len(test_dataset), len(test_dataset)/lt\n",
    "print('Total data: {} ({:.2f}%)\\nTrain data: {} ({:.2f}%)\\nVal Data:   {}  ({:.2f}%)\\nTest Data:  {}  ({:.2f}%)'.format(lt,lt/lt,ltr,ptr,lvd,pvd,lts,pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=params['BATCH_SIZE'], num_workers=params[\"N_WORKERS\"])# , shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=params['BATCH_SIZE'], num_workers=params[\"N_WORKERS\"])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=params['BATCH_SIZE'], num_workers=params[\"N_WORKERS\"])\n",
    "\n",
    "# train_dataloader = MLCDataLoader(train_dataset, params['BATCH_SIZE'])\n",
    "# val_dataloader = MLCDataLoader(val_dataset, params['BATCH_SIZE'])\n",
    "# test_dataloader = MLCDataLoader(test_dataset, params['BATCH_SIZE'])\n",
    "\n",
    "test_freq = int(len(train_dataset)/params['BATCH_SIZE'])\n",
    "\n",
    "num_train_batches = int(np.ceil(len(train_dataset) / params['BATCH_SIZE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = GetModelNM(len(train_dataset.classes), params['BACKBONE'], params['MODEL_FREEZE'], params['I_WEIGHTS'])\n",
    "# Switch model to the training mode and move it to GPU.\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['LR'], weight_decay=params['WEIGHT_DECAY'])\n",
    "\n",
    "# If more than one GPU is available we can use both to speed up the training.\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "os.makedirs(params['SAVE_PATH'], exist_ok=True)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/rubsini/ApplePlantDiseases/e/APD-20\n"
     ]
    }
   ],
   "source": [
    "# Logging metadata\n",
    "import neptune\n",
    "# from neptune.new.types import File  \n",
    "NEPTUNE_API_TOKEN = 'Insert KEY Here'\n",
    "run = neptune.init_run(project=f'{params[\"OWNER\"]}/{params[\"PROJECT\"]}',\n",
    "                    api_token=NEPTUNE_API_TOKEN,\n",
    "                    tags = params['EXP_TYPE'])\n",
    "\n",
    "run['parameters'] = params\n",
    "# run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "epoch: 0 iter:  0 TEST: micro f1: 0.309 macro f1: 0.194 samples f1: 0.312 uap: 0.527\n",
      "epoch: 0 iter:815 TEST: micro f1: 0.511 macro f1: 0.481 samples f1: 0.389 uap: 0.897\n",
      "epoch: 0 iter:816 train: loss:0.359\n",
      "epoch: 0 iter:816 TRAIN: micro f1: 0.511 macro f1: 0.481 samples f1: 0.389 uap: 0.897\n",
      "saved & uploaded checkpoint: Checkpoints/checkpoint-000000.pth\n",
      "Epoch:  1\n",
      "epoch: 1 iter:1630 TEST: micro f1: 0.592 macro f1: 0.575 samples f1: 0.485 uap: 0.907\n",
      "epoch: 1 iter:1632 train: loss:0.301\n",
      "epoch: 1 iter:1632 TRAIN: micro f1: 0.889 macro f1: 0.500 samples f1: 0.917 uap: 1.000\n",
      "Epoch:  2\n",
      "epoch: 2 iter:2445 TEST: micro f1: 0.617 macro f1: 0.607 samples f1: 0.516 uap: 0.913\n",
      "epoch: 2 iter:2448 train: loss:0.288\n",
      "epoch: 2 iter:2448 TRAIN: micro f1: 0.889 macro f1: 0.500 samples f1: 0.917 uap: 1.000\n",
      "Epoch:  3\n",
      "epoch: 3 iter:3260 TEST: micro f1: 0.623 macro f1: 0.609 samples f1: 0.526 uap: 0.916\n",
      "epoch: 3 iter:3264 train: loss:0.283\n",
      "epoch: 3 iter:3264 TRAIN: micro f1: 0.571 macro f1: 0.278 samples f1: 0.417 uap: 1.000\n",
      "Epoch:  4\n",
      "epoch: 4 iter:4075 TEST: micro f1: 0.626 macro f1: 0.620 samples f1: 0.527 uap: 0.917\n",
      "epoch: 4 iter:4080 train: loss:0.279\n",
      "epoch: 4 iter:4080 TRAIN: micro f1: 0.571 macro f1: 0.333 samples f1: 0.500 uap: 0.947\n",
      "Epoch:  5\n",
      "epoch: 5 iter:4890 TEST: micro f1: 0.630 macro f1: 0.615 samples f1: 0.539 uap: 0.914\n",
      "epoch: 5 iter:4896 train: loss:0.277\n",
      "epoch: 5 iter:4896 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.667 uap: 1.000\n",
      "Epoch:  6\n",
      "epoch: 6 iter:5705 TEST: micro f1: 0.634 macro f1: 0.624 samples f1: 0.541 uap: 0.918\n",
      "epoch: 6 iter:5712 train: loss:0.273\n",
      "epoch: 6 iter:5712 TRAIN: micro f1: 0.571 macro f1: 0.333 samples f1: 0.500 uap: 1.000\n",
      "Epoch:  7\n",
      "epoch: 7 iter:6520 TEST: micro f1: 0.637 macro f1: 0.627 samples f1: 0.546 uap: 0.918\n",
      "epoch: 7 iter:6528 train: loss:0.273\n",
      "epoch: 7 iter:6528 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.750 uap: 1.000\n",
      "Epoch:  8\n",
      "epoch: 8 iter:7335 TEST: micro f1: 0.639 macro f1: 0.628 samples f1: 0.549 uap: 0.920\n",
      "epoch: 8 iter:7344 train: loss:0.272\n",
      "epoch: 8 iter:7344 TRAIN: micro f1: 1.000 macro f1: 0.667 samples f1: 1.000 uap: 1.000\n",
      "Epoch:  9\n",
      "epoch: 9 iter:8150 TEST: micro f1: 0.641 macro f1: 0.635 samples f1: 0.548 uap: 0.922\n",
      "epoch: 9 iter:8160 train: loss:0.271\n",
      "epoch: 9 iter:8160 TRAIN: micro f1: 0.571 macro f1: 0.333 samples f1: 0.417 uap: 1.000\n",
      "Epoch:  10\n",
      "epoch:10 iter:8965 TEST: micro f1: 0.639 macro f1: 0.631 samples f1: 0.548 uap: 0.920\n",
      "epoch:10 iter:8976 train: loss:0.271\n",
      "epoch:10 iter:8976 TRAIN: micro f1: 0.889 macro f1: 0.611 samples f1: 0.917 uap: 1.000\n",
      "Epoch:  11\n",
      "epoch:11 iter:9780 TEST: micro f1: 0.637 macro f1: 0.629 samples f1: 0.543 uap: 0.920\n",
      "epoch:11 iter:9792 train: loss:0.270\n",
      "epoch:11 iter:9792 TRAIN: micro f1: 0.889 macro f1: 0.500 samples f1: 0.917 uap: 1.000\n",
      "Epoch:  12\n",
      "epoch:12 iter:10595 TEST: micro f1: 0.642 macro f1: 0.638 samples f1: 0.551 uap: 0.920\n",
      "epoch:12 iter:10608 train: loss:0.269\n",
      "epoch:12 iter:10608 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.750 uap: 1.000\n",
      "Epoch:  13\n",
      "epoch:13 iter:11410 TEST: micro f1: 0.638 macro f1: 0.633 samples f1: 0.540 uap: 0.921\n",
      "epoch:13 iter:11424 train: loss:0.269\n",
      "epoch:13 iter:11424 TRAIN: micro f1: 0.750 macro f1: 0.500 samples f1: 0.667 uap: 0.989\n",
      "Epoch:  14\n",
      "epoch:14 iter:12225 TEST: micro f1: 0.641 macro f1: 0.633 samples f1: 0.550 uap: 0.921\n",
      "epoch:14 iter:12240 train: loss:0.268\n",
      "epoch:14 iter:12240 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.750 uap: 1.000\n",
      "Epoch:  15\n",
      "epoch:15 iter:13040 TEST: micro f1: 0.644 macro f1: 0.635 samples f1: 0.552 uap: 0.921\n",
      "epoch:15 iter:13056 train: loss:0.268\n",
      "epoch:15 iter:13056 TRAIN: micro f1: 0.889 macro f1: 0.611 samples f1: 0.917 uap: 0.968\n",
      "Epoch:  16\n",
      "epoch:16 iter:13855 TEST: micro f1: 0.645 macro f1: 0.642 samples f1: 0.553 uap: 0.923\n",
      "epoch:16 iter:13872 train: loss:0.268\n",
      "epoch:16 iter:13872 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.750 uap: 1.000\n",
      "Epoch:  17\n",
      "epoch:17 iter:14670 TEST: micro f1: 0.640 macro f1: 0.635 samples f1: 0.550 uap: 0.921\n",
      "epoch:17 iter:14688 train: loss:0.269\n",
      "epoch:17 iter:14688 TRAIN: micro f1: 0.750 macro f1: 0.500 samples f1: 0.667 uap: 1.000\n",
      "Epoch:  18\n",
      "epoch:18 iter:15485 TEST: micro f1: 0.638 macro f1: 0.631 samples f1: 0.541 uap: 0.921\n",
      "epoch:18 iter:15504 train: loss:0.268\n",
      "epoch:18 iter:15504 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.750 uap: 1.000\n",
      "Epoch:  19\n",
      "epoch:19 iter:16300 TEST: micro f1: 0.643 macro f1: 0.637 samples f1: 0.557 uap: 0.921\n",
      "epoch:19 iter:16320 train: loss:0.267\n",
      "epoch:19 iter:16320 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.667 uap: 1.000\n",
      "Epoch:  20\n",
      "epoch:20 iter:17115 TEST: micro f1: 0.639 macro f1: 0.630 samples f1: 0.549 uap: 0.919\n",
      "epoch:20 iter:17136 train: loss:0.271\n",
      "epoch:20 iter:17136 TRAIN: micro f1: 0.889 macro f1: 0.611 samples f1: 0.917 uap: 1.000\n",
      "Epoch:  21\n",
      "epoch:21 iter:17930 TEST: micro f1: 0.645 macro f1: 0.635 samples f1: 0.554 uap: 0.921\n",
      "epoch:21 iter:17952 train: loss:0.268\n",
      "epoch:21 iter:17952 TRAIN: micro f1: 0.889 macro f1: 0.611 samples f1: 0.917 uap: 1.000\n",
      "Epoch:  22\n",
      "epoch:22 iter:18745 TEST: micro f1: 0.646 macro f1: 0.642 samples f1: 0.557 uap: 0.922\n",
      "epoch:22 iter:18768 train: loss:0.267\n",
      "epoch:22 iter:18768 TRAIN: micro f1: 0.571 macro f1: 0.333 samples f1: 0.500 uap: 1.000\n",
      "Epoch:  23\n",
      "epoch:23 iter:19560 TEST: micro f1: 0.644 macro f1: 0.638 samples f1: 0.556 uap: 0.920\n",
      "epoch:23 iter:19584 train: loss:0.270\n",
      "epoch:23 iter:19584 TRAIN: micro f1: 0.750 macro f1: 0.444 samples f1: 0.750 uap: 1.000\n",
      "Epoch:  24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m# for n in range(len(train_dataloader)):\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m#     imgs, targets = train_dataloader[n]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m     model_result \u001b[39m=\u001b[39m model(imgs)\n\u001b[0;32m     16\u001b[0m     loss \u001b[39m=\u001b[39m criterion(model_result, targets\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat))\n\u001b[0;32m     18\u001b[0m     batch_loss_value \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mario\\Github\\Personal\\ApplePlantPathology\\repo\\backbones.py:88\u001b[0m, in \u001b[0;36mGetModelNM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_model(x)\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torchvision\\models\\resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[0;32m    273\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[1;32m--> 274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[0;32m    276\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(x)\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torchvision\\models\\resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    144\u001b[0m     identity \u001b[39m=\u001b[39m x\n\u001b[1;32m--> 146\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m    147\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[0;32m    148\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\mario\\anaconda3\\envs\\AppleDis\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "epoch = 0\n",
    "iteration = 0\n",
    "best_macro_F1 = 0.0\n",
    "while True:\n",
    "    print('Epoch: ', epoch)\n",
    "    batch_losses = []\n",
    "    for imgs, targets in train_dataloader:\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_result = model(imgs)\n",
    "        loss = criterion(model_result, targets.type(torch.float))\n",
    "\n",
    "        batch_loss_value = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run[\"logs/lr\"].log(optimizer.param_groups[0]['lr'])\n",
    "        run[\"logs/loss_step\"].log(loss)\n",
    "\n",
    "        batch_losses.append(batch_loss_value)\n",
    "        with torch.no_grad():\n",
    "            uap = compute_tracking_metrics(targets.cpu().numpy(), torch.sigmoid(model_result).cpu().numpy())\n",
    "            run[\"logs/train_uap\"].log(uap)\n",
    "            result = sklearn_metrics(torch.sigmoid(model_result).cpu().numpy(), targets.cpu().numpy())\n",
    "            # for metric in result:\n",
    "                #  run[\"logs/train_\"+metric.replace('/','_')].log(result[metric])\n",
    "\n",
    "        if iteration % test_freq == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                model_result = []\n",
    "                targets = []\n",
    "                for imgs, batch_targets in val_dataloader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    model_batch_result = torch.sigmoid(model(imgs))\n",
    "                    model_result.extend(model_batch_result.cpu().numpy())\n",
    "                    targets.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "            result = sklearn_metrics(np.array(model_result), np.array(targets))\n",
    "            # res_macro_F1 = result['macro/f1']\n",
    "            uap = compute_tracking_metrics(np.array(targets), np.array(model_result))\n",
    "            run[\"logs/validation_uap\"].log(uap)\n",
    "            res_macro_F1 =  uap\n",
    "            #for metric in result:\n",
    "                # logger.add_scalar('test/' + metric, result[metric], iteration)\n",
    "            #    run[\"logs/test_\"+metric.replace('/','_')].log(result[metric])\n",
    "            print(\"epoch:{:2d} iter:{:3d} TEST: \"\n",
    "                    \"micro f1: {:.3f} \"\n",
    "                    \"macro f1: {:.3f} \"\n",
    "                    \"samples f1: {:.3f} \"\n",
    "                    \"uap: {:.3f}\".format(epoch, iteration,\n",
    "                                                result['micro/f1'],\n",
    "                                                result['macro/f1'],\n",
    "                                                result['samples/f1'],\n",
    "                                                uap))\n",
    "\n",
    "            model.train()\n",
    "        iteration += 1\n",
    "\n",
    "    loss_value = np.mean(batch_losses)\n",
    "    run[\"logs/loss_epoch\"].log(loss_value)\n",
    "    print(\"epoch:{:2d} iter:{:3d} train: loss:{:.3f}\".format(epoch, iteration, loss_value))\n",
    "    print(\"epoch:{:2d} iter:{:3d} TRAIN: \"\n",
    "                \"micro f1: {:.3f} \"\n",
    "                \"macro f1: {:.3f} \"\n",
    "                \"samples f1: {:.3f} \"\n",
    "                \"uap: {:.3f}\".format(epoch, iteration,\n",
    "                                            result['micro/f1'],\n",
    "                                            result['macro/f1'],\n",
    "                                            result['samples/f1'],\n",
    "                                            uap))\n",
    "    if best_macro_F1 < res_macro_F1 or epoch % params['SAVE_FREQ'] == 0:\n",
    "        if best_macro_F1 <= res_macro_F1:\n",
    "            best_macro_F1 = res_macro_F1\n",
    "            s_model, s_epoch = model, epoch\n",
    "    if epoch % params['SAVE_FREQ'] == 0:\n",
    "        checkpoint_save(s_model, params['SAVE_PATH'], s_epoch, run)\n",
    "    epoch += 1\n",
    "    if params['EPOCHS'] < epoch:\n",
    "        break\n",
    "\n",
    "#params[\"EXP_TYPE\"][0] = params[\"EXP_TYPE\"][1]+\"/\"+params[\"EXP_TYPE\"][0]\n",
    "os.makedirs(params[\"SAVE_DIR\"]+\"/\"+params[\"EXP_TYPE\"][0], exist_ok=True)\n",
    "params[\"RUN\"] = run\n",
    "params[\"PAT_NAMES\"] = [i.capitalize() for i in list(train_dataset.classes)] # list(mapping.keys())\n",
    "print('PARAMS --> PAT_NAMES', params['PAT_NAMES'])\n",
    "res = [i.start() for i in re.finditer('/', run.get_url())]\n",
    "params['EXP_NAME'] = run.get_url()[max(res)+1:]\n",
    "best_epoch = max(get_filenames_of_path(pathlib.Path('Checkpoints')))\n",
    "model.load_state_dict(torch.load(best_epoch))\n",
    "params['BEST_EPOCH'] = [int(s) for s in best_epoch.name.split('-')[1].split('.') if s.isdigit()][0]\n",
    "evaluate(model, val_dataloader, test_dataloader, params)\n",
    "\n",
    "run.stop()\n",
    "shutil.rmtree(\"Checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/rubsini/ApplePlantDiseases/e/APD-20/metadata\n"
     ]
    }
   ],
   "source": [
    "run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppleDis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07c9baaa5fee94e55ae7848f03186a5b55c5e95cae62ad9c463687cd4660a001"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
